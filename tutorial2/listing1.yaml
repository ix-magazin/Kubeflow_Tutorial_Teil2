apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "kserve-iris"
spec:
  predictor:
    minReplicas: 0
    maxReplicas: 2
    model:
      modelFormat:
        name: sklearn
      storageUri: "gs://kfserving-examples/models/sklearn/1.0/model"
      runtime: kserve-sklearnserver
      runtimeVersion: v0.8.0
      name: kserve-container
      protocolVersion: v1
      resources:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 64Mi 